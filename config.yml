# --- 项目和路径配置 ---
project_name: "sdp_wifi_sensing" # 项目名称，用于日志和模型保存
dataset_root: "datasets" # 原始数据集的根目录

# 随机种子，用于确保实验的可复现性
seed: 42

# --- 数据预处理与加载配置 ---
# 预处理后的数据存放根目录
preprocessed_data_dir: "datasets/predata"

# 需要进行预处理的原始数据场景列表
scenes_to_process:
  - "Home_Scene1"
  - "Home_Scene2"

# 数据集划分策略配置
data_split:
  # 划分策略, 可选值:
  # 'preprocess': 在预处理阶段按文件组划分。更科学，避免数据泄露。
  # 'on_the_fly': 训练时动态随机划分。更灵活，但可能存在轻微数据泄露。
  strategy: 'on_the_fly'
  # 验证集所占比例 (仅在 'on_the_fly' 策略下生效)
  val_size: 0.2

# 参与训练的数据源（对应 preprocessed_data_dir 下的子目录名）
# 可以是单个场景，也可以是多个场景的组合。
# 使用 'all' 关键字可以自动包含所有已处理的场景。
training_data_sources:
  - "Home_Scene1"

# 每个2秒时间窗内，保留的最大数据包数量
# 如果数据包数量不足，会进行零填充
max_packets_per_interval: 70

# --- 模型配置 ---
model:
  name: "vit" # 模型选择，可选: "simple_transformer", "vit"
  
  # --- 模型通用参数 ---
  input_channels: 16 # 输入特征图的通道数 (2个房间 * (4个实部dB流 + 4个虚部dB流))
  feature_dim: 250 # 特征维度 (即每个天线流的子载波数量)
  num_classes: 3 # 分类任务的类别数 (即房间数量)
  embed_dim: 256 # Transformer模型的内部嵌入维度
  num_heads: 8 # Transformer中的多头注意力头数
  num_layers: 6 # Transformer编码器的层数
  hidden_dim: 1024 # Transformer前馈网络的隐藏层维度
  dropout: 0.1 # Dropout比例

# --- ViT (Vision Transformer) 专属配置 ---
vit:
  # Vision Transformer 的 Patch 大小。
  # 可以是单个整数（例如 10，代表 10x10 的方形Patch），
  # 也可以是 [height, width] 格式的列表（例如 [4, 25]，代表 4x25 的矩形Patch）。
  patch_size: [7, 10]

# --- 训练过程配置 ---
training:
  # 保存的最佳模型的文件名。
  # 支持占位符: {project_name}, {model_name}, {timestamp}
  model_save_name: "{project_name}_{model_name}_{timestamp}_best.pth"
  
  # 训练的总轮数
  epochs: 500
  batch_size: 512 # 每个批次的大小
  learning_rate: 0.0001 # 学习率
  optimizer: "AdamW" # 优化器类型
  weight_decay: 0.01 # 权重衰减 (L2正则化)
  patience: 100 # 早停(Early Stopping)的耐心轮数，即连续N轮验证集损失没有改善后停止训练
  
  # 每隔多少个epoch记录一次可视化结果（如混淆矩阵）
  log_every_n_epochs: 10
  
  # --- 损失函数配置 ---
  # 用于BCE损失的类别权重，手动设置为一个预估值，用于缓解类别不平衡问题
  # 计算方式: pos_weight = 负样本数 / 正样本数
  pos_weight: [4.4, 4, 3.5]
  
  # 损失函数组合配置, 可以配置一个或多个损失函数及其权重
  loss_components:
    - name: "bce"    # 名称: 'bce' (二元交叉熵)
      weight: 0.5    # 在总损失中的权重
      params: {}     # 'bce'会自动使用上面的全局pos_weight
    - name: "focal"  # 名称: 'focal' (焦点损失)
      weight: 0.5    # 在总损失中的权重
      params:
        alpha: 0.25  # Focal Loss的alpha参数
        gamma: 2.0   # Focal Loss的gamma参数

# --- 环境与运行配置 ---
gpus: "0,1,2,3" # 使用的GPU设备ID (例如 "0" 或 "0,1")
num_workers: 4 # 数据加载器使用的工作进程数 